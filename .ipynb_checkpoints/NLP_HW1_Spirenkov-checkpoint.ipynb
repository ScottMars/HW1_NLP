{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Бинарная классификация диалогов Оператор-Клиент Дилерского центра.\n",
    "### pymystem3 + FastText\n",
    "### Таргет: Продажа состоялась (1) / Продажа не состоялась (0)\n",
    "### Выполнил: Сергей Спиренков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ПРЕДОБРАБОТКА"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Приведение данных к табличному - DataFrame виду"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# data = pd.read_csv('./test_data.txt', header = None)\n",
    "data = pd.read_csv('./train.txt', header = None, error_bad_lines=False)\n",
    "test_data = pd.read_csv('./test.txt', header = None, error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Формирую лейблы\n",
    "def lable_text_extractor(data):\n",
    "    keys_list = ['LABEL=1', 'LABEL=0']\n",
    "    dialog_features = ('OPER', 'CLI')\n",
    "    sep_dialog = ']'\n",
    "    corpus = {}\n",
    "    curr_key = None\n",
    "    num_lab = 0\n",
    "    num_ph = 0\n",
    "\n",
    "    for i, row in data.iterrows():\n",
    "        string = data[0].loc[i]\n",
    "        if any(word in string for word in keys_list):\n",
    "            curr_key = str(num_lab) + \"_\" + string\n",
    "            num_lab += 1\n",
    "            corpus[curr_key] = {}\n",
    "            num_ph = 0\n",
    "\n",
    "        if string.startswith('OPER'):\n",
    "            temp_key = 'OPER_' + str(num_ph)\n",
    "            num_ph += 1\n",
    "            corpus[curr_key][temp_key] = string[string.index(sep_dialog) + 2:]\n",
    "        if string.startswith('CLI'):\n",
    "            temp_key = 'CLI_' + str(num_ph)\n",
    "            num_ph += 1\n",
    "            corpus[curr_key][temp_key] = string[string.index(sep_dialog) + 2:]\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "corpus = lable_text_extractor(data)\n",
    "test_corpus = lable_text_extractor(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_corpus\n",
    "\n",
    "# Пример вывода:\n",
    "# {'0_LABEL=0': {'CLI_0': 'да алло',\n",
    "#   'OPER_1': 'группа компаний реактор доброе утро меня зовут Владислав оставляли заявку на нашем сайте планируете покупку нового авто марки Volkswagen',\n",
    "#   'CLI_2': 'да я хотел сначала официальный дилер volkswagen или нет',\n",
    "#   'OPER_3': 'конечно же мы являемся официальным дилером флаги',\n",
    "#   'CLI_4': 'а',\n",
    "#   'OPER_5': 'конечно',\n",
    "#   'CLI_6': 'понятно да',\n",
    "#   'OPER_7': 'скажите',"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Произвожу очистку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "# Очищаю строки от мусора\n",
    "\n",
    "\n",
    "def del_garb(corpus):\n",
    "    for lab_key in corpus.keys():\n",
    "        # print(\"\\n\", lab_key, sep = \"\")\n",
    "        for speaker_key in corpus[lab_key].keys():\n",
    "            temp = re.sub(r\"[0-9]{1,}-[0-9,а-я,А-Я]{1,}\", \"\", corpus[lab_key][speaker_key])\n",
    "            temp = re.sub(r\"[.]\", \"\", temp)\n",
    "            temp = re.sub(r\"[0-9]\", \"\", temp)\n",
    "            temp = re.sub(r\"[ ]{1,}\", \" \", temp)\n",
    "            if temp.endswith(\" \"):\n",
    "                temp = temp[:-1]\n",
    "            if temp.startswith(\" \"):\n",
    "                temp = temp[1:]\n",
    "            corpus[lab_key][speaker_key] = temp\n",
    "    return corpus\n",
    "             print(speaker_key, \":\", corpus[lab_key][speaker_key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "corpus = del_garb(corpus)\n",
    "test_corpus = del_garb(test_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# разбиваю предложения на слова\n",
    "\n",
    "def own_tokenizer(corpus):\n",
    "    for lab_key in corpus.keys():\n",
    "        # print(\"\\n\", lab_key, sep = \"\")\n",
    "        for speaker_key in corpus[lab_key].keys():\n",
    "            corpus[lab_key][speaker_key] = corpus[lab_key][speaker_key].split()\n",
    "        # print(speaker_key, \":\", corpus[lab_key][speaker_key])\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "corpus = own_tokenizer(corpus)\n",
    "test_corpus = own_tokenizer(test_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Объединяю диалоги в цепочку\n",
    "\n",
    "def concat_dialogs(corpus):\n",
    "    concat_phrases = {}\n",
    "\n",
    "    for lab_key in corpus.keys():\n",
    "        # num_phr = 0\n",
    "        concat_phrases[lab_key] = []\n",
    "        for i in range(len(corpus[lab_key].keys())):\n",
    "            for speaker_key in corpus[lab_key].keys():\n",
    "                if speaker_key.endswith(str(i)):\n",
    "                    concat_phrases[lab_key].extend(corpus[lab_key][speaker_key])\n",
    "                    break\n",
    "        concat_phrases[lab_key] = \" \".join(concat_phrases[lab_key]).lower()\n",
    "    return concat_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "concat_phr = concat_dialogs(corpus)\n",
    "test_concat_phr = concat_dialogs(test_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_concat_phr\n",
    "\n",
    "# {'0_LABEL=0': 'да алло группа компаний реактор доброе\n",
    "# утро меня зовут владислав оставляли заявку на нашем сайте\n",
    "# планируете покупку нового авто марки volkswagen да я хотел\n",
    "# сначала официальный дилер volkswagen или нет конечно же мы\n",
    "# являемся официальным дилером флаги а конечно понятно да скажите\n",
    "# ... ',\n",
    "# '1_LABEL=0': 'алло добрый день меня зовут виктория группа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Перевожу в pd.DataFrame\n",
    "df = pd.DataFrame(list(concat_phr.items()), columns = [\"Target\",\"Document\"] )\n",
    "test_df = pd.DataFrame(list(test_concat_phr.items()), columns = [\"Target\",\"Document\"] )\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Функция меняет str значение LABEL=.. на int 0 / 1\n",
    "def changeVal(x):\n",
    "  if x.endswith(\"LABEL=1\"):\n",
    "    x = 1\n",
    "  else:\n",
    "    x = 0\n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Меняю значения таргета на 0 / 1\n",
    "df[\"Target\"] = df[\"Target\"].map(lambda x: changeVal(x))\n",
    "test_df[\"Target\"] = test_df[\"Target\"].map(lambda x: changeVal(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_df[\"Document\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лемматизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pymystem3 import Mystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_copy = df.copy()\n",
    "test_df_copy = test_df.copy()\n",
    "m = Mystem()\n",
    "\n",
    "# Лемматизирую строки библиотекой Яндекса\n",
    "def lemmatize_str(sent, myStemObj):\n",
    "    lemmat_list = []\n",
    "\n",
    "    lemmas = myStemObj.lemmatize(sent)\n",
    "    for i in lemmas:\n",
    "        if i.isalpha():\n",
    "            lemmat_list.append(i)\n",
    "    return lemmat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_copy[\"Document\"] = df_copy[\"Document\"].map(lambda x: lemmatize_str(x, m))\n",
    "test_df_copy[\"Document\"] = test_df_copy[\"Document\"].map(lambda x: lemmatize_str(x, m))\n",
    "df_copy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удаляю stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Смотрю сколько слов в диалогах df_copy\n",
    "for num_sent in range(4):\n",
    "    temp_num = len(df_copy[\"Document\"].loc[num_sent])\n",
    "    print(f\"Dialog number: {num_sent}, word's amount: {temp_num}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Качаю список стоп слов с ресурса на гитхабе\n",
    "r = requests.get('https://raw.githubusercontent.com/stopwords-iso/stopwords-ru/master/stopwords-ru.txt')\n",
    "stop_list = r.text.split()\n",
    "\n",
    "# Импортирую список стоп слов из NLTK словаря и дополняю гитхабовским\n",
    "stopWords = stopwords.words('russian')\n",
    "print(\"Длина словаря стоп слов NLTK:\", len(stopWords), type(stopWords))\n",
    "stopWords.extend(stop_list)\n",
    "stopWords = list(set(stopWords))\n",
    "\n",
    "print(\"Длина итогового словаря стоп слов:\", len(stopWords), type(stopWords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "num_sent = 0\n",
    "temp_num = len(df_copy[\"Document\"].loc[num_sent])\n",
    "\n",
    "temp_dialog_list = df_copy[\"Document\"].loc[num_sent]\n",
    "print(\"Before:\", len(temp_dialog_list))\n",
    "print(temp_dialog_list)\n",
    "temp_dialog_list = [word for word in temp_dialog_list if not word in stopWords]\n",
    "print(\"After:\", len(temp_dialog_list))\n",
    "print(temp_dialog_list)\n",
    "\n",
    "# Функция для удаления stop words во всем корпусе диалогов\n",
    "def stop_words_remover(corpus, stopWords, col):\n",
    "    for num_sent in range(len(corpus)):\n",
    "        temp_dialog_list = corpus[col].loc[num_sent]\n",
    "        temp_dialog_list = [word for word in temp_dialog_list if not word in stopWords]\n",
    "        corpus[col].loc[num_sent] = temp_dialog_list\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_copy # датасет\n",
    "stopWords # список стоп слов\n",
    "dialog_column = 'Document' # название колонки диалогов\n",
    "\n",
    "df_copy = stop_words_remover(df_copy, stopWords, dialog_column)\n",
    "test_df_copy = stop_words_remover(test_df_copy, stopWords, dialog_column)\n",
    "\n",
    "test_df_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for num_sent in range(4):\n",
    "    temp_num = len(df_copy[\"Document\"].loc[num_sent])\n",
    "    print(f\"Dialog number: {num_sent}, word's amount: {temp_num}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_copy[\"Document\"].loc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FAST TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Преобразую данные в читаемый для FastText формат\n",
    "\n",
    "fasttext_set = df_copy.copy()\n",
    "fasttext_test_set = test_df_copy.copy()\n",
    "\n",
    "fasttext_set['Document'] = df_copy['Document'].apply(lambda x: \" \".join(x))\n",
    "fasttext_test_set['Document'] = test_df_copy['Document'].apply(lambda x: \" \".join(x))\n",
    "\n",
    "fasttext_set['Target'] = df_copy['Target'].apply(lambda x: \"__label__\" + str(x))\n",
    "fasttext_test_set['Target'] = test_df_copy['Target'].apply(lambda x: \"__label__\" + str(x))\n",
    "\n",
    "fasttext_test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Сохраняю в txt файл данные, на которых будет обучаться датасет\n",
    "\n",
    "fasttext_set[['Target', 'Document']].to_csv('fasttext_set.txt', header=False, index=False, sep=\"\\t\")\n",
    "fasttext_test_set[['Target', 'Document']].to_csv('fasttext_test_set.txt', header=False, index=False, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Обучаю модель FastText\n",
    "\n",
    "model = fasttext.train_supervised(input='fasttext_set.txt', epoch=400, wordNgrams = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = fasttext.load_model(\"model_bigram_150_ep_09227.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = fasttext_test_set['Document'].apply(lambda x: model.predict(x, k=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(y_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Преобразую predict в веткор чисел\n",
    "\n",
    "y_vals = list(fasttext_test_set['Target'].apply(lambda x: 1 if x == '__label__1' else 0))\n",
    "\n",
    "y_pred_vals = list(map(lambda x: x[0][0], y_pred))\n",
    "y_pred_vals = list(map(lambda x: 1 if x == '__label__1' else 0, y_pred_vals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "# Считаю F1 score\n",
    "\n",
    "print(classification_report(y_vals, y_pred_vals))\n",
    "print(\"F1 score:\", f1_score(y_vals, y_pred_vals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Результаты отбора параметров:\n",
    "\n",
    "* 20 эп - 0.8796068796068797\n",
    "* 100 эп - 0.8905852417302799\n",
    "* 400 эп - 0.8934010152284264\n",
    "* 1000 эп - 0.8911392405063292\n",
    "\n",
    "* 50 эп би-грамы - 0.9072681704260651\n",
    "* 100 эп би-грамы - 0.915\n",
    "* 150 эп би-грамы - 0.9226932668329176 BEST\n",
    "* 200 эп би-грамы - 0.9226932668329176"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
